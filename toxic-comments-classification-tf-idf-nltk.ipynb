{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8076,"databundleVersionId":44219,"sourceType":"competition"}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-06T20:03:56.357379Z","iopub.execute_input":"2024-05-06T20:03:56.357746Z","iopub.status.idle":"2024-05-06T20:03:57.354493Z","shell.execute_reply.started":"2024-05-06T20:03:56.357713Z","shell.execute_reply":"2024-05-06T20:03:57.353614Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip', index_col='id')\n\ndf_test = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:03:59.648680Z","iopub.execute_input":"2024-05-06T20:03:59.649666Z","iopub.status.idle":"2024-05-06T20:04:02.801736Z","shell.execute_reply.started":"2024-05-06T20:03:59.649623Z","shell.execute_reply":"2024-05-06T20:04:02.800702Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:04:02.803704Z","iopub.execute_input":"2024-05-06T20:04:02.804402Z","iopub.status.idle":"2024-05-06T20:04:02.808774Z","shell.execute_reply.started":"2024-05-06T20:04:02.804365Z","shell.execute_reply":"2024-05-06T20:04:02.807871Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df_train, df_test])","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:04:02.810028Z","iopub.execute_input":"2024-05-06T20:04:02.810439Z","iopub.status.idle":"2024-05-06T20:04:02.839048Z","shell.execute_reply.started":"2024-05-06T20:04:02.810404Z","shell.execute_reply":"2024-05-06T20:04:02.838280Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train['comment_text'] = df_train['comment_text'].str.lower()\ndf_test['comment_text'] = df_test['comment_text'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:04:02.840737Z","iopub.execute_input":"2024-05-06T20:04:02.841022Z","iopub.status.idle":"2024-05-06T20:04:03.343046Z","shell.execute_reply.started":"2024-05-06T20:04:02.840997Z","shell.execute_reply":"2024-05-06T20:04:03.342028Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:04:03.344252Z","iopub.execute_input":"2024-05-06T20:04:03.344532Z","iopub.status.idle":"2024-05-06T20:04:03.392579Z","shell.execute_reply.started":"2024-05-06T20:04:03.344508Z","shell.execute_reply":"2024-05-06T20:04:03.391778Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 159571 entries, 0000997932d777bf to fff46fc426af1f9a\nData columns (total 7 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   comment_text   159571 non-null  object\n 1   toxic          159571 non-null  int64 \n 2   severe_toxic   159571 non-null  int64 \n 3   obscene        159571 non-null  int64 \n 4   threat         159571 non-null  int64 \n 5   insult         159571 non-null  int64 \n 6   identity_hate  159571 non-null  int64 \ndtypes: int64(6), object(1)\nmemory usage: 9.7+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\n\ndef remove_special_characters(text):\n    text = re.sub(r'http\\S+', ' ', text )\n    text = re.sub(r'[^\\w\\s]', ' ', text)\n    text = re.sub(r'\\bhttps?://[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)+\\b', ' ', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    text = re.sub(r'\\d', ' ', text)  # Corrected line\n    text= re.sub(r'[\\u4e00-\\u9fff]+', ' ', text)\n    return text\n\ndf_train['comment_text'] = df_train['comment_text'].apply(remove_special_characters)\ndf_test['comment_text'] = df_test['comment_text'].apply(remove_special_characters)\n\nprint(df_train['comment_text'].head(100))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:04:21.654794Z","iopub.execute_input":"2024-05-06T20:04:21.655509Z","iopub.status.idle":"2024-05-06T20:04:48.181139Z","shell.execute_reply.started":"2024-05-06T20:04:21.655477Z","shell.execute_reply":"2024-05-06T20:04:48.180280Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"id\n0000997932d777bf    explanation why the edits made under my userna...\n000103f0d9cfb60f    d aww he matches this background colour i m se...\n000113f07ec002fd    hey man i m really not trying to edit war it s...\n0001b41b1c6bb37e    more i can t make any real suggestions on impr...\n0001d958c54c6e35    you sir are my hero any chance you remember wh...\n00025465d4725e87    congratulations from me as well use the tools ...\n0002bcb3da6cb337         cocksucker before you piss around on my work\n00031b1e95af7921    your vandalism to the matt shirvington article...\n00037261f536c51d    sorry if the word nonsense was offensive to yo...\n00040093b2687caa    alignment on this subject and which are contra...\n0005300084f90edc    fair use rationale for image wonju jpg thanks ...\n00054a5e18b50dd4    bbq be a man and lets discuss it maybe over th...\n0005c987bdfc9d4b    hey what is it talk what is it an exclusive gr...\n0006f16e4e9f292e    before you start throwing accusations and warn...\n00070ef96486d6f9    oh and the girl above started her arguments wi...\n00078f8ce7eb276d    juelz santanas age in      juelz santana was  ...\n0007e25b2121310b    bye don t look come or think of comming back t...\n000897889268bc93      redirect talk voydan pop georgiev chernodrinski\n0009801bd85e5806    the mitsurugi point made no sense why not argu...\n0009eaea3325de8c    don t mean to bother you i see that you re wri...\n000b08c464718505    regarding your recent edits once again please ...\n000bfd0867774845    good to know about me yeah i m studying now deepu\n000c0dfd995809fa    snowflakes are not always symmetrical under ge...\n000c6a3f0cd3ba8e    the signpost    september      read this signp...\n000cfee90f50d471    re considering  st paragraph edit i don t unde...\n000eefc67a2c930f    radial symmetry several now extinct lineages i...\n000f35deef84dc4a    there s no need to apologize a wikipedia artic...\n000ffab30195c5e1    yes because the mother of the child in the cas...\n0010307a3a50a353    ok but it will take a bit of work but i can t ...\n0010833a96e1f886    a barnstar for you the real life barnstar lets...\n0011cc71398479c4    how could i post before the block expires the ...\n00128363e367d703    not sure about a heading of fight for freedom ...\n001325b8b20ea8aa    praise looked at this article about   months a...\n001363e1dbe91225    i was able to post the above list so quickly b...\n0013a8b1a5f26bcb    well not before the process but before how we ...\n00148d055a169b93    not at all you are making a straw man argument...\n00151a9f93c6b059    mainland asia includes the lower basin of chin...\n0015f4aa35ebe9b5    pretty much everyone from warren county surrou...\n00169857adbc989b    hi explicit can you block o fenian for edit wa...\n0016e01b742b8da3    notability of rurika kasuga a tag has been pla...\n001735f961a23fc4    sure but the lead must briefly summarize armen...\n00173958f46763a2    tfd i think we just eced i think we responded ...\n001810bf8c45bf5f    you are gay or antisemmitian archangel white t...\n00190820581d90ce               fuck your filthy mother in the ass dry\n001956c382006abd    i m sorry i m sorry i screwed around with some...\n001b2dd65d9d925c    i don t believe the lisak criticism present th...\n001c419c445b5a59    you had a point and it s now ammended with app...\n001c557175094f10    in other words you re too lazy to actually poi...\n001cadfd324f8087    as for your claims of stalking that is absolut...\n001d874a4d3e8813    jmabel in regards to predominant scholary cons...\n001d8e7be417776a    bi you said you wanted to talk at the bottom o...\n001dc38a83d420cf    get fucked up get fuckeeed up got a drink that...\n001e89eb3f0b0915    are you threatening me for disputing neutralit...\n001ee16c46a99262    thanks undeletion was more than i d hoped for ...\n001ffdcc3e7fb49c    awesome then i ll simply disregard your notice...\n0020e7119b96eeeb    stupid peace of shit stop deleting my stuff as...\n0020fd96ed3b8c8b    tony sidaway is obviously a fistfuckee he love...\n00218d74784ce50b    ga review ii i m sorry to say this but i have ...\n0021fe88bc4da3e6    my band page s deletion you thought i was gone...\n002264ea4d5f2887    why can t you believe how fat artie is did you...\n00229d44f41f3acb    locking this page would also violate wp newbie...\n0022cf8467ebc9fd    a bisexual like a homosexual or a heterosexual...\n0023daf96917e0d0                    redirect talk frank herbert mason\n002746baedcdff10    christian arabs hi could you please stop enfor...\n00280c0d0652b366    dh dude abc officially says this is the name f...\n0028d62e8a5629aa    all of my edits are good cunts like you who re...\n00290e2a171dd073    neiln s bang on you aren t being harassed at a...\n002918ae66cc4bc2    i went there around the same time he did and t...\n0029541a38c523a0    there must be some chemical imbalance in your ...\n0029b87aa9c7dc4a    parzival    you are trying to scare thatso how...\n002a13f2896596fa    oppose as the article stands it does not prope...\n002a6beca33307b3    i would appreciate an apology from both of you...\n002b90cc8a94c76b    they are not original research they are pointe...\n002c9cccf2f1d05b    ambiguous so mabuska irish can mean more than ...\n002d6c9d9f85e81f    while the magazine s masthead says time the co...\n002e2d3db2b597c4    take your belated and piffling prevarications ...\n002f0e29c60807b1    that s what i m looking through it looks like ...\n0030614cfd96d9d1    in the same direction is it really necessary t...\n00316bcc0d1bc6e0       december      utc you must not play metal g...\n003217c3eb469ba9    hi i am back again last warning stop undoing m...\n00328eadb85b3010    minimization of textile effluent a proposed de...\n0033b9d5ccd499fb    is it scientific to attribute an event a to ca...\n0034065c7b12a7a2    screwjob hey i noticed your comments on the mo...\n00349c6325526c11    april      thank you for experimenting with th...\n0034d7c78cfa6dee    christ iq is selected for therefore every popu...\n0035d638ba684122    can you prove it isn t if you had a better kno...\n0036621e4c7e10b5    would you both shut up you don t run wikipedia...\n0036e50f42d0b679         oh it s me vandalising xd see here greetings\n0037e59caead9dab    website hey all i was thinking of getting myse...\n0037fe4f8f5cdcfb                             thanks reading there now\n0038d1dc2ad29469    personal attacks in fruit brute vfd my apologi...\n0038f191ffc93d75    transliteration of russian place names in writ...\n003910ffa2f50517    almost got me too i had to look it up to see i...\n00397b264deba890    how can one defame someone who thinks the fort...\n003a19c04c079bf7    lack of balance this article is seriously out ...\n003b9f448ee4a29d    thanks i can see that violating clearly stated...\n003bd094feef5263     hi thanks for our kind words see you around talk\n003caacc6ce6c9e9    collusion in poker this is regarded as most he...\n003d77a20601cec1    thanks much however if it s been resolved why ...\n003dbd1b9b354c1f    you can do all you re doing right now but if y...\nName: comment_text, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"import string \nfrom nltk import word_tokenize\n\ndf_train['tokens'] = df_train['comment_text'].apply(word_tokenize)\ndf_test['tokens'] = df_test['comment_text'].apply(word_tokenize)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:05:32.624358Z","iopub.execute_input":"2024-05-06T20:05:32.625077Z","iopub.status.idle":"2024-05-06T20:08:29.623597Z","shell.execute_reply.started":"2024-05-06T20:05:32.625043Z","shell.execute_reply":"2024-05-06T20:08:29.622702Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, valid = train_test_split(df_train, train_size=0.8, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:08:48.115336Z","iopub.execute_input":"2024-05-06T20:08:48.116272Z","iopub.status.idle":"2024-05-06T20:08:48.170179Z","shell.execute_reply.started":"2024-05-06T20:08:48.116230Z","shell.execute_reply":"2024-05-06T20:08:48.169367Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk import word_tokenize\n\nvec = TfidfVectorizer(ngram_range=(1, 2), \n                      min_df=3, \n                      max_df=0.9, \n                      strip_accents='unicode', \n                      use_idf=1,\n                      smooth_idf=1, \n                      sublinear_tf=1,\n                      binary=1,\n                      stop_words='english')\ntrn_term_doc = vec.fit_transform(df_train['comment_text'])\nval_term_doc = vec.transform(valid['comment_text'])\ntest_term_doc = vec.transform(df_test['comment_text'])","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:08:56.732845Z","iopub.execute_input":"2024-05-06T20:08:56.733491Z","iopub.status.idle":"2024-05-06T20:09:34.688715Z","shell.execute_reply.started":"2024-05-06T20:08:56.733461Z","shell.execute_reply":"2024-05-06T20:09:34.687752Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:558: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"x = trn_term_doc\nval_x = val_term_doc","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:09:36.963912Z","iopub.execute_input":"2024-05-06T20:09:36.964842Z","iopub.status.idle":"2024-05-06T20:09:36.968778Z","shell.execute_reply.started":"2024-05-06T20:09:36.964795Z","shell.execute_reply":"2024-05-06T20:09:36.967884Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:09:38.102333Z","iopub.execute_input":"2024-05-06T20:09:38.102722Z","iopub.status.idle":"2024-05-06T20:09:38.107166Z","shell.execute_reply.started":"2024-05-06T20:09:38.102692Z","shell.execute_reply":"2024-05-06T20:09:38.106159Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"epsilon = 1e-9  # Define epsilon as a small positive constant\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:09:39.383122Z","iopub.execute_input":"2024-05-06T20:09:39.383867Z","iopub.status.idle":"2024-05-06T20:09:39.389147Z","shell.execute_reply.started":"2024-05-06T20:09:39.383828Z","shell.execute_reply":"2024-05-06T20:09:39.388133Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Define a function to calculate the probability of each word given a specific class (toxic or non-toxic)\ndef probability(y_i, y):\n    # Sum the occurrences of each word in comments labeled with y_i (1 for toxic, 0 for non-toxic)\n    occurences = x[y == y_i].sum(0)\n    # Add a smoothing factor of 1 to avoid division by zero and handle words not present in some classes\n    \n    return (occurences + 1) / ((y == y_i).sum() + 1)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:09:40.093064Z","iopub.execute_input":"2024-05-06T20:09:40.093410Z","iopub.status.idle":"2024-05-06T20:09:40.098549Z","shell.execute_reply.started":"2024-05-06T20:09:40.093382Z","shell.execute_reply":"2024-05-06T20:09:40.097681Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Define a function to train a logistic regression model for binary classification (toxic or non-toxic)\ndef get_model(y):\n    # Convert the target labels to a numpy array\n    y = y.values\n    # Calculate the log-ratio of probabilities of each word being toxic vs. non-toxic\n    loga = np.log((probability(1, y) + epsilon) / (probability(0, y) + epsilon) )\n    # Multiply the input features by the log-ratio to incorporate the information about word toxicity\n    x_loga = x.multiply(loga)\n    # Initialize a naive bayes model with specified hyperparameters\n    model = LogisticRegression(C=1.0,  # Regularization parameter\n                                    penalty='l2',  # Penalty term ('l1' or 'l2')\n                                    solver='liblinear',  # Optimization algorithm\n                                    max_iter=100,  # Maximum number of iterations\n                                    random_state=42)\n    \n    # Fit the model to the modified input features and target labels\n    return model.fit(x_loga, y), loga","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:09:41.042592Z","iopub.execute_input":"2024-05-06T20:09:41.043297Z","iopub.status.idle":"2024-05-06T20:09:41.049517Z","shell.execute_reply.started":"2024-05-06T20:09:41.043266Z","shell.execute_reply":"2024-05-06T20:09:41.048472Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ntrain_labels = df_train.drop([ 'comment_text'], axis = 1)\nvalid_labels = valid.drop([ 'comment_text'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:09:42.526935Z","iopub.execute_input":"2024-05-06T20:09:42.527686Z","iopub.status.idle":"2024-05-06T20:09:42.546535Z","shell.execute_reply.started":"2024-05-06T20:09:42.527655Z","shell.execute_reply":"2024-05-06T20:09:42.545668Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"  # Dictionary to store ROC AUC scores for each class\nmodel = {}\nROC_AUC_Scores = {}\nfor i, col in enumerate(classes):\n    print(col)\n\n    # Train model for current class\n    model_trained, loga = get_model(train_labels[col])\n    model[col] = (model_trained, loga)\n    # Make predictions on validation set\n    preds = model_trained.predict(val_x.multiply(loga)).reshape(-1, 1)\n\n    # Calculate ROC AUC score for current class and store it\n    roc_auc = roc_auc_score(valid_labels[col], preds)\n    ROC_AUC_Scores[col] = roc_auc\n    # Print ROC AUC scores for each class\nfor col, roc_auc in ROC_AUC_Scores.items():\n    print(f\"ROC AUC for class: '{col}': {roc_auc}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:09:43.534284Z","iopub.execute_input":"2024-05-06T20:09:43.534926Z","iopub.status.idle":"2024-05-06T20:10:39.115501Z","shell.execute_reply.started":"2024-05-06T20:09:43.534893Z","shell.execute_reply":"2024-05-06T20:10:39.114493Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"toxic\nsevere_toxic\nobscene\nthreat\ninsult\nidentity_hate\nROC AUC for class: 'toxic': 0.8821352063989041\nROC AUC for class: 'severe_toxic': 0.8593699620003561\nROC AUC for class: 'obscene': 0.9121859131542873\nROC AUC for class: 'threat': 0.9661534041186063\nROC AUC for class: 'insult': 0.8711052432334527\nROC AUC for class: 'identity_hate': 0.8808416950158198\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.zeros((len(df_test), len(classes)))\n\nfor i, col in enumerate(classes):\n    print(col)\n    preds[:, i] = model[col][0].predict_proba(test_term_doc.multiply(model[col][1]))[:, 1]","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:10:43.218375Z","iopub.execute_input":"2024-05-06T20:10:43.218739Z","iopub.status.idle":"2024-05-06T20:10:44.534431Z","shell.execute_reply.started":"2024-05-06T20:10:43.218712Z","shell.execute_reply":"2024-05-06T20:10:44.533687Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"toxic\nsevere_toxic\nobscene\nthreat\ninsult\nidentity_hate\n","output_type":"stream"}]},{"cell_type":"code","source":"submid = pd.DataFrame({'id': df_test.index})  # Use index as 'id' column\nsubmission = pd.concat([submid, pd.DataFrame(preds, columns=classes)], axis=1)\nsubmission.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:10:46.417557Z","iopub.execute_input":"2024-05-06T20:10:46.418393Z","iopub.status.idle":"2024-05-06T20:10:48.448740Z","shell.execute_reply.started":"2024-05-06T20:10:46.418359Z","shell.execute_reply":"2024-05-06T20:10:48.447946Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:10:57.461542Z","iopub.execute_input":"2024-05-06T20:10:57.461892Z","iopub.status.idle":"2024-05-06T20:10:57.480962Z","shell.execute_reply.started":"2024-05-06T20:10:57.461866Z","shell.execute_reply":"2024-05-06T20:10:57.479925Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                 id     toxic  severe_toxic   obscene    threat    insult  \\\n0  00001cee341fdb12  0.999950      0.077125  0.999502  0.005494  0.965543   \n1  0000247867823ef7  0.005032      0.001199  0.003409  0.000412  0.005956   \n2  00013b17ad220c46  0.012519      0.000839  0.004402  0.000413  0.006708   \n3  00017563c3f7919a  0.004256      0.000925  0.003341  0.000551  0.003943   \n4  00017695ad8997eb  0.026761      0.001160  0.005383  0.000411  0.008904   \n\n   identity_hate  \n0       0.186210  \n1       0.001228  \n2       0.001066  \n3       0.000840  \n4       0.001018  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001cee341fdb12</td>\n      <td>0.999950</td>\n      <td>0.077125</td>\n      <td>0.999502</td>\n      <td>0.005494</td>\n      <td>0.965543</td>\n      <td>0.186210</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000247867823ef7</td>\n      <td>0.005032</td>\n      <td>0.001199</td>\n      <td>0.003409</td>\n      <td>0.000412</td>\n      <td>0.005956</td>\n      <td>0.001228</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00013b17ad220c46</td>\n      <td>0.012519</td>\n      <td>0.000839</td>\n      <td>0.004402</td>\n      <td>0.000413</td>\n      <td>0.006708</td>\n      <td>0.001066</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00017563c3f7919a</td>\n      <td>0.004256</td>\n      <td>0.000925</td>\n      <td>0.003341</td>\n      <td>0.000551</td>\n      <td>0.003943</td>\n      <td>0.000840</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017695ad8997eb</td>\n      <td>0.026761</td>\n      <td>0.001160</td>\n      <td>0.005383</td>\n      <td>0.000411</td>\n      <td>0.008904</td>\n      <td>0.001018</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}